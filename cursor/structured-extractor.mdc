---
description: "Structured information extraction expert. Use when: extracting business rules, event flows, state machines, constraints, entities, and relations from code/docs/logs. Provides: (1) 6 extraction type framework (2) Few-shot templates (3) 5-step Python post-processing pipeline (4) 3 output formats (JSON/Markdown/Knowledge Graph)."
globs: []
alwaysApply: false
---

# Structured Extractor

> Universal structured information extraction | Built on Google LangExtract's algorithm layer | 5-step pipeline + 3 output formats

## Skill Root (IMPORTANT)

This skill is installed at: **`.cursor/skills/structured-extractor/`**

When referencing any file below, prefix with this path. For example:
- `references/few-shot-templates.md` → `.cursor/skills/structured-extractor/references/few-shot-templates.md`
- `scripts/pipeline.py` → `.cursor/skills/structured-extractor/scripts/pipeline.py`

| Resource | Path |
|----------|------|
| Few-shot templates | `.cursor/skills/structured-extractor/references/few-shot-templates.md` |
| Extraction types | `.cursor/skills/structured-extractor/references/extraction-types.md` |
| Output schema | `.cursor/skills/structured-extractor/references/output-schema.md` |
| Pipeline docs | `.cursor/skills/structured-extractor/references/post-processing.md` |
| Pipeline script | `.cursor/skills/structured-extractor/scripts/pipeline.py` |
| Presets dir | `.cursor/skills/structured-extractor/assets/presets/` |

## Core Rules (CRITICAL)

1. **Never skip Few-shot** - Extractions MUST follow the template format in `references/few-shot-templates.md`
2. **Never free-form output** - Strictly follow the JSON schema in `references/output-schema.md`
3. **Never skip post-processing** - Raw extractions MUST go through `scripts/pipeline.py`
4. **Never output low quality** - Filter extractions with `confidence < 0.3` regardless of output format

## Extraction Types

| Type | Recognition Pattern |
|------|-------------------|
| `rule` | Conditional branches, business decisions (if/switch/when) |
| `event` | Event subscriptions, message sending (+=, Fire, Send) |
| `state` | State changes, phase transitions (SetState, enum change) |
| `constraint` | Null checks, boundary conditions, precondition assertions |
| `entity` | Class definitions, key concepts, named actors |
| `relation` | Inter-entity relationships (inheritance, dependency, calls) |

## Output Format (per extraction)

```json
{
  "id": "ext_001",
  "type": "rule",
  "text": "if (MLevel.IsGuideLevel)",
  "summary_cn": "Special handling for tutorial levels",
  "attributes": {
    "condition": "IsGuideLevel == true",
    "action": "Auto-deploy and enter battle"
  },
  "source_file": "AMultiGateLevel.cs"
}
```

## Decision Tree

```
I need to extract structured information from text?
    |
    +-- What file type?
    |   +-- .cs/.py/.js/.ts -> Use code-logic preset
    |   +-- .md/.txt/.doc   -> Use doc-structure preset
    |   +-- .log            -> Use log-analysis preset
    |   +-- Other           -> Specify focus_types manually
    |
    +-- Which post-processing?
    |   +-- Basic (default) -> Grounding + Dedup + Scoring
    |   +-- Full            -> All 5 steps
    |   +-- Minimal         -> Scoring only
    |
    +-- Output format? (ask user after pipeline)
        +-- JSON file       -> Save pipeline output (default, always available)
        +-- Markdown report -> Generate human-readable .md (always available)
        +-- KG injection    -> Call aim_create_entities (requires KG MCP tools)
```

## Workflow

### Step 1: Select preset

Read the appropriate preset from the skill root:

```
.cursor/skills/structured-extractor/assets/presets/
  code-logic.json       Focus: rule, event, state, constraint
  doc-structure.json    Focus: entity, relation, rule, constraint
  log-analysis.json     Focus: event, state, constraint
```

### Step 2: Extract with AI

Read `.cursor/skills/structured-extractor/references/few-shot-templates.md` for examples.

For each item found:
- `text` MUST be an exact substring from the original source (not rewritten)
- `summary_cn` is the human-readable summary
- `attributes` varies by type (see `references/extraction-types.md`)

### Step 3: Save raw JSON

Save Claude/AI extractions to a temporary JSON file.

**Input format**: Accepts both:
- Array: `[{"id": "ext_001", ...}, ...]`
- Object: `{"extractions": [{"id": "ext_001", ...}, ...]}`

### Step 4: Run pipeline

```bash
# Basic
python .cursor/skills/structured-extractor/scripts/pipeline.py \
  --input raw.json --source code.cs --output result.json

# With preset
python .cursor/skills/structured-extractor/scripts/pipeline.py \
  --input raw.json --source code.cs \
  --config .cursor/skills/structured-extractor/assets/presets/code-logic.json \
  --output result.json

# Full pipeline
python .cursor/skills/structured-extractor/scripts/pipeline.py \
  --input raw.json --source code.cs \
  --enable-entity-resolution --enable-relation-inference \
  --output result.json
```

### Step 5: Choose output format

After pipeline completes, ask user which format(s) they want:

| Format | Description | Dependency |
|--------|-------------|------------|
| **JSON file** | Save pipeline output as `.json` | None (always available) |
| **Markdown report** | Human-readable `.md` report | None (always available) |
| **KG injection** | Call `aim_create_entities` | Requires KG MCP tools |

## Pipeline Steps

```
1. Source Grounding  -> Locate text in source (char_start/end + line)
2. Overlap Dedup     -> Remove duplicate extractions (>50% overlap)
3. Confidence Score  -> 4-dimension quality scoring
4. Entity Resolution -> Merge similar entities (optional)
5. Relation Inference -> Infer co-occurrence relations (optional)
```

For algorithm details, read `.cursor/skills/structured-extractor/references/post-processing.md`.

## Key Principles

1. **Few-shot driven** - Extraction quality depends on templates, not free-form
2. **Pipeline required** - Raw extractions lack location and confidence scores
3. **text must be verbatim** - The `text` field is an exact source substring, never rewritten

## Red Flags

| Signal | Correct Action |
|--------|---------------|
| "Just output Markdown directly" | Must do JSON extraction + pipeline first |
| "I don't need Few-shot" | Must follow template format or pipeline fails |
| "I rewrote the text field" | text must be exact source substring; use summary_cn for summaries |
| "No need to run pipeline.py" | Raw extractions lack location and confidence |
| "I'll write location manually" | Location is computed by Source Grounding algorithm |
| "Set all confidence to 1.0" | Confidence is computed by 4-dimension algorithm |
| "Just inject into KG directly" | User may not have KG tools; ask for output format first |
